{
    "datasets": ["main", "p1", "p2"],
    "gsm_types": ["gsm8-std", "gsm-symbolic"],
    "models": ["meta-llama/llama-3.1-70b-instruct", "meta-llama/llama-3.1-8b-instruct", "openai/gpt-4o-mini-2024-07-18"],
    "max_reflection_layers": 3,
    "auto_prompt_model": "same",
    "run_test": true,
    "run_analysis": true
}